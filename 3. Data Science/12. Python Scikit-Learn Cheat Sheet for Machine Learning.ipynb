{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Scikit-Learn Cheat Sheet for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is an open source Python library used for machine learning, preprocessing, cross-validation and visualization algorithms. It provides a range of supervised and unsupervised learning algorithms in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic Example\n",
    "Load the data...\n",
    "Divide the data into train and test...\n",
    "Train your data using the KNN Algorithm and...\n",
    "Predict the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "import numpy as np\n",
    "X = np.random.random((10,5))\n",
    "y = np.array(['M','M','F','F','M','F','M','M','F','F','F'])\n",
    "X[X < 0.7] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X,y = iris.data[:,:2], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 33)\n",
    "\n",
    "scalar = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization :\n",
    "\n",
    "Data standardization is one of the data preprocessing step which is used for rescaling one or more attributes so that the attributes have a mean value of 0 and a standard deviation of 1. Standardization assumes that your data has a Gaussian (bell curve) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler().fit(X_train)\n",
    "standardized_X = scalar.transform(X_train)\n",
    "standardized_X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization :\n",
    "\n",
    "Normalization is a technique generally used for data preparation for machine learning. The main goal of normalization is to change the values of numeric columns in the dataset so that we can have a common scale, without losing the information or distorting the differences in the ranges of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scalar = Normalizer().fit(X_train)\n",
    "normalized_X = scalar.transform(X_train)\n",
    "normalized_X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarization :\n",
    "    \n",
    "Binarization is a common operation performed on text count data. Using binarization the analyst can decide to consider the presence or absence of a feature rather than having a quantified number of occurrences for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binary_X = binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Categorical Features :\n",
    "    \n",
    "The LabelEncoder is another class used in data-preprocessing for encoding class levels. It can also be used to transform non-numerical labels into numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing missing values :\n",
    "    \n",
    "The Imputer class in python will provide you with the basic strategies for imputing/filling missing values. It does this by using the mean, median values or the most frequent value of the row or column in which the missing values are located. This class also allows for encoding different missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diwakar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.91090798, -1.59775374],\n",
       "       [-1.0271058 ,  0.08448757],\n",
       "       [ 0.59966379, -1.59775374],\n",
       "       [ 0.01867465, -0.96691325],\n",
       "       [ 0.48346596, -0.33607276],\n",
       "       [-1.25950146,  0.29476773],\n",
       "       [-1.37569929,  0.71532806],\n",
       "       [-0.79471015, -1.17719341],\n",
       "       [-1.14330363,  0.71532806],\n",
       "       [ 2.45882905,  1.55644871],\n",
       "       [-0.79471015,  0.71532806],\n",
       "       [-0.79471015,  1.34616854],\n",
       "       [-0.21372101, -0.33607276],\n",
       "       [ 0.83205945, -0.1257926 ],\n",
       "       [-0.44611666,  1.76672887],\n",
       "       [ 1.41304859,  0.29476773],\n",
       "       [ 0.01867465, -0.54635292],\n",
       "       [ 2.22643339, -0.96691325],\n",
       "       [-0.32991883, -1.17719341],\n",
       "       [ 0.13487248,  0.29476773],\n",
       "       [-1.0271058 ,  1.13588838],\n",
       "       [-1.49189712, -1.59775374],\n",
       "       [ 0.59966379, -0.54635292],\n",
       "       [-1.60809495, -0.33607276],\n",
       "       [-0.91090798,  1.13588838],\n",
       "       [ 1.64544425, -0.1257926 ],\n",
       "       [ 0.25107031,  0.71532806],\n",
       "       [ 0.48346596, -1.8080339 ],\n",
       "       [ 1.8778399 , -0.54635292],\n",
       "       [ 1.18065293, -0.1257926 ],\n",
       "       [ 0.71586162, -0.54635292],\n",
       "       [-0.09752318, -1.17719341],\n",
       "       [-0.91090798,  0.92560822],\n",
       "       [-0.79471015,  1.55644871],\n",
       "       [ 1.18065293, -0.54635292],\n",
       "       [-0.67851232, -0.75663309],\n",
       "       [-0.79471015,  1.55644871],\n",
       "       [-0.21372101, -1.17719341],\n",
       "       [ 0.36726814, -0.1257926 ],\n",
       "       [ 0.94825728, -0.33607276],\n",
       "       [ 0.71586162, -0.54635292],\n",
       "       [-1.72429277, -0.1257926 ],\n",
       "       [ 1.64544425,  1.13588838],\n",
       "       [-0.79471015,  0.92560822],\n",
       "       [ 0.59966379, -1.17719341],\n",
       "       [-1.60809495,  0.29476773],\n",
       "       [ 2.11023556, -0.1257926 ],\n",
       "       [ 0.71586162,  0.29476773],\n",
       "       [-0.79471015,  1.55644871],\n",
       "       [ 0.83205945,  0.29476773],\n",
       "       [ 0.59966379, -0.75663309],\n",
       "       [-0.91090798,  0.92560822],\n",
       "       [-0.67851232,  0.71532806],\n",
       "       [ 0.71586162, -0.75663309],\n",
       "       [ 0.01867465,  1.97700903],\n",
       "       [-0.09752318,  2.81812969],\n",
       "       [-1.37569929,  0.29476773],\n",
       "       [ 1.29685076,  0.08448757],\n",
       "       [ 0.59966379, -0.33607276],\n",
       "       [-0.32991883,  0.92560822],\n",
       "       [-0.09752318, -0.96691325],\n",
       "       [-0.91090798,  0.50504789],\n",
       "       [ 0.25107031, -1.8080339 ],\n",
       "       [-1.0271058 , -0.1257926 ],\n",
       "       [-0.91090798, -2.22859423],\n",
       "       [ 0.94825728, -0.1257926 ],\n",
       "       [-0.09752318, -0.54635292],\n",
       "       [-0.32991883, -0.96691325],\n",
       "       [-0.32991883, -1.59775374],\n",
       "       [-1.14330363,  0.08448757],\n",
       "       [ 0.25107031, -0.33607276],\n",
       "       [-0.91090798, -0.1257926 ],\n",
       "       [ 1.29685076,  0.08448757],\n",
       "       [ 1.06445511, -1.17719341],\n",
       "       [-0.56231449,  1.34616854],\n",
       "       [-0.67851232,  2.1872892 ],\n",
       "       [-0.91090798,  0.71532806],\n",
       "       [-1.37569929,  1.13588838],\n",
       "       [ 2.22643339,  1.55644871],\n",
       "       [ 1.76164208, -0.33607276],\n",
       "       [-1.37569929,  0.08448757],\n",
       "       [-0.32991883, -1.38747358],\n",
       "       [ 0.01867465, -0.75663309],\n",
       "       [ 1.06445511,  0.50504789],\n",
       "       [ 0.01867465, -0.75663309],\n",
       "       [-0.44611666,  1.34616854],\n",
       "       [-0.91090798,  0.71532806],\n",
       "       [ 0.25107031, -0.75663309],\n",
       "       [-0.09752318, -0.54635292],\n",
       "       [ 0.36726814, -0.54635292],\n",
       "       [-0.79471015,  0.50504789],\n",
       "       [-0.21372101, -0.1257926 ],\n",
       "       [-0.44611666, -0.1257926 ],\n",
       "       [-0.44611666,  1.76672887],\n",
       "       [ 1.06445511,  0.50504789],\n",
       "       [-1.0271058 , -1.17719341],\n",
       "       [ 0.48346596,  0.71532806],\n",
       "       [-0.32991883, -1.38747358],\n",
       "       [ 2.22643339, -0.54635292],\n",
       "       [-0.44611666,  0.71532806],\n",
       "       [ 1.06445511, -0.1257926 ],\n",
       "       [-0.32991883,  2.39756936],\n",
       "       [-0.91090798,  0.29476773],\n",
       "       [-1.14330363, -0.1257926 ],\n",
       "       [ 0.01867465, -0.75663309],\n",
       "       [ 0.13487248, -0.1257926 ],\n",
       "       [ 1.52924642, -0.1257926 ],\n",
       "       [-1.0271058 , -1.38747358],\n",
       "       [ 0.59966379, -1.17719341],\n",
       "       [-0.21372101, -0.1257926 ],\n",
       "       [ 2.22643339, -0.1257926 ],\n",
       "       [-0.44611666,  0.71532806]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values=0, strategy='mean', axis=0)\n",
    "imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Polynomial Features :\n",
    "    \n",
    "Polynomial Feature generates a new feature matrix which consists of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], then the 2-degree polynomial features are [1, a, b, a^2, ab, b^2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.10000000e+00, 3.50000000e+00, ...,\n",
       "        1.11517875e+03, 7.65318750e+02, 5.25218750e+02],\n",
       "       [1.00000000e+00, 4.90000000e+00, 3.00000000e+00, ...,\n",
       "        6.48270000e+02, 3.96900000e+02, 2.43000000e+02],\n",
       "       [1.00000000e+00, 4.70000000e+00, 3.20000000e+00, ...,\n",
       "        7.23845120e+02, 4.92830720e+02, 3.35544320e+02],\n",
       "       ...,\n",
       "       [1.00000000e+00, 6.50000000e+00, 3.00000000e+00, ...,\n",
       "        1.14075000e+03, 5.26500000e+02, 2.43000000e+02],\n",
       "       [1.00000000e+00, 6.20000000e+00, 3.40000000e+00, ...,\n",
       "        1.51084576e+03, 8.28528320e+02, 4.54354240e+02],\n",
       "       [1.00000000e+00, 5.90000000e+00, 3.00000000e+00, ...,\n",
       "        9.39870000e+02, 4.77900000e+02, 2.43000000e+02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(5)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning Estimator :\n",
    "    \n",
    "Supervised learning is a type of machine learning that enables the model to predict future outcomes after they are trained on labelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression Algorithm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "\n",
    "\n",
    "# Naive Bayes Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "\n",
    "# KNN Algorithm\n",
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Learning Estimator :\n",
    "    \n",
    "Unsupervised learning is a type of machine learning that enables the model to predict future outcomes without being trained on the labelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "\n",
    "# K Means Clustering Algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Fitting  :\n",
    "\n",
    "Fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Supervised learning\n",
    "\n",
    "lr.fit(X, y) #Fits data into the model\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# For Unsupervised Learning\n",
    "\n",
    "k_means.fit(X_train)#Fits data into the model\n",
    "pca_model = pca.fit_transform(X_train) #Fit to data, then transform it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction :\n",
    "    \n",
    "Fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 5 should be equal to 2, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-07622002ca39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# For Supervised learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#predict label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#predict label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#estimate probablity of a label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \"\"\"\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \"\"\"\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    472\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    473\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 5 should be equal to 2, the number of features at training time"
     ]
    }
   ],
   "source": [
    "# For Supervised learning\n",
    "y_pred=svc.predict(np.random.random((2,5))) #predict label\n",
    "\n",
    "y_pred=lr.predict(X_test) #predict label\n",
    "y_pred=knn.predict_proba(X_test)#estimate probablity of a label\n",
    "\n",
    "\n",
    "# For Unsupervised Learning\n",
    "y_pred=k_means.predict(X_test) #predict labels in clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Metrics :\n",
    "    \n",
    "The sklearn.metrics module implements several loss, score, and utility functions to measure classification performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = [3, -0.5, 2]\n",
    "mean_absolute_error(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² Score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Metrics :\n",
    "    \n",
    "The sklearn.metrics module implements several loss, score, and utility functions to measure regression performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Score\n",
    "knn.score(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted Rand Index\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "# Homogeneity\n",
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score(y_true, y_pred)\n",
    "\n",
    "# V-measure\n",
    "from sklearn.metrics import v_measure_score\n",
    "metrics.v_measure_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score \n",
    "\n",
    "print(cross_val_score(knn, X_train, y_train, cv=4)) \n",
    "print(cross_val_score(lr, X, y, cv=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search :\n",
    "    \n",
    "GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\"n_neighbors\": np.arange(1,3), \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "grid = GridSearchCV(estimator=knn, param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Parameter Optimization :\n",
    "    \n",
    "RandomizedSearchCV performs the random search on hyper parameters. In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "params = {\"n_neighbours\": range(1,5), \"weights\":[\"uniform\", \"distance\"]}\n",
    "rserach = RandomizedSearchCV(estimator=knn,param_distribution=params, cv=4, n_iter=8, random_state=5)\n",
    "rsearch.fit(X_train, Y_train)\n",
    "\n",
    "print(rsearch.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
